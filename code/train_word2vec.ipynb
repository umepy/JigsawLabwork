{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"from collections import defaultdict\nimport gensim\nimport pandas as pd\nfrom spacy.lang.en import English\nnlp = English()","execution_count":1,"outputs":[{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/smart_open/ssh.py:34: UserWarning: paramiko missing, opening SSH/SCP/SFTP paths will be disabled.  `pip install paramiko` to suppress\n  warnings.warn('paramiko missing, opening SSH/SCP/SFTP paths will be disabled.  `pip install paramiko` to suppress')\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = pd.read_csv(\"../input/train.csv\")\ntest_df = pd.read_csv(\"../input/train.csv\")\nall_document = train_df[\"comment_text\"]+test_df[\"comment_text\"]\n# kaggle だとメモリ足らない\ndel train_df, test_df","execution_count":2,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"#nlp の箇所は word.split() や nltk.word_torknize でも可\n#その場合は sentences = [line.split() for line in all_document]\n#token.text を使えば original text が入手可能\n#lemma:見出し語 pos_:品詞 dep_:依存関係\ndocument_info = [[token.lemma, token.pos_, token.dep_] for line in all_document for token in nlp(line)]\ndocument_info [:5]\n#list を転置して lemma のみ取得\nsentences = list(map(list, zip(*document_info)))\nsentences[:5]\nword_count = defaultdict(lambda: 0)\nfor line in sentences:\n    for word in line:\n        word_count[word] += 1\nword_count\nsentences =  [token[0] if word_count[token[0]] >= MIN_COUNT token[1] for line in document_info for token in line]"},{"metadata":{"trusted":true},"cell_type":"code","source":"# line.split() はnltk.word_torknize(line) でも可\nsentences = [line.split() for line in all_document]","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"MIN_COUNT = 10","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"word2vec = gensim.models.Word2Vec(sentences, window=5, min_count=MIN_COUNT , iter=5, negative=5)","execution_count":6,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"word2vec.save(\"jigsaw_word2vec\")","execution_count":7,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"word2vec.wv.most_similar(\"suck\")","execution_count":10,"outputs":[{"output_type":"execute_result","execution_count":10,"data":{"text/plain":"[('screw', 0.7839298844337463),\n ('soak', 0.7812076807022095),\n ('blow', 0.761015772819519),\n ('gobble', 0.7414670586585999),\n ('lighten', 0.7212039232254028),\n ('pick', 0.6987291574478149),\n ('Suck', 0.6884019374847412),\n ('grow', 0.6851153373718262),\n ('crank', 0.6800088882446289),\n ('sucking', 0.6752239465713501)]"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}