{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['train.csv', 'sample_submission.csv', 'test.csv']\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"../input\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chainer\n",
    "from chainer import datasets\n",
    "from chainer import functions as F\n",
    "from chainer import links as L\n",
    "from chainer import Variable\n",
    "from chainer.backends import cuda\n",
    "from sklearn.model_selection import train_test_split\n",
    "xp = cuda.cupy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5min 14s, sys: 8.62 s, total: 5min 23s\n",
      "Wall time: 5min 23s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_df = pd.read_csv(\"../input/train.csv\")\n",
    "test_df = pd.read_csv(\"../input/test.csv\")\n",
    "all_df = pd.concat([train_df['comment_text'], test_df['comment_text']])\n",
    "\n",
    "t_all = []\n",
    "for s in all_df:\n",
    "    t_all.append(s.split())\n",
    "del all_df\n",
    "\n",
    "words = {}\n",
    "for j in range(len(t_all)):\n",
    "    for word in t_all[j]:\n",
    "        if word not in words:\n",
    "            words[word] = len(words)\n",
    "del t_all\n",
    "\n",
    "t_train = []\n",
    "for s in train_df['comment_text']:\n",
    "    t_train.append(s.split())\n",
    "\n",
    "X = []\n",
    "for j in range(len(t_train)):\n",
    "    vector = []\n",
    "    for word in t_train[j]:\n",
    "        vector.append(words[word])\n",
    "    vector = xp.array(vector, dtype=xp.int32)\n",
    "    X.append(vector)\n",
    "del t_train\n",
    "\n",
    "t_test = []\n",
    "for s in test_df['comment_text']:\n",
    "    t_test.append(s.split())\n",
    "\n",
    "X_pre = []\n",
    "for j in range(len(t_test)):\n",
    "    vector = []\n",
    "    for word in t_test[j]:\n",
    "        vector.append(words[word])\n",
    "    vector = xp.array(vector, dtype=xp.int32)\n",
    "    X_pre.append(vector)\n",
    "del t_test\n",
    "del test_df\n",
    "\n",
    "del words\n",
    "del vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 28s, sys: 1.84 s, total: 3min 29s\n",
      "Wall time: 3min 30s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "max_len_train = max(list(map(len, X)))\n",
    "max_len_test = max(list(map(len, X_pre)))\n",
    "max_len = max_len_train if max_len_train>max_len_test else max_len_test\n",
    "del max_len_train\n",
    "del max_len_test\n",
    "\n",
    "for i in range(len(X)):\n",
    "    add = xp.zeros((max_len-len(X[i])), dtype=xp.int32)\n",
    "    X[i] = xp.hstack((X[i], add))\n",
    "\n",
    "for i in range(len(X_pre)):\n",
    "    add = xp.zeros((max_len-len(X_pre[i])), dtype=xp.int32)\n",
    "    X_pre[i] = xp.hstack((X_pre[i], add))\n",
    "\n",
    "del add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y= np.where(train_df['target']>0.5, 1, 0)\n",
    "y = xp.array(y, dtype=xp.int32)\n",
    "del train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class jigsaw_dataset(chainer.dataset.DatasetMixin):\n",
    "    def __init__(self, X, y, train=True, min_count=10, train_size=0.6):\n",
    "        \n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(X, y, train_size=train_size, random_state=1)\n",
    "        self.n_train = len(self.y_train)\n",
    "        self.n_test = len(self.y_test)\n",
    "        self.train = train\n",
    "        self.train_size=train_size\n",
    "    \n",
    "    def __len__(self):\n",
    "        if self.train:\n",
    "            return self.n_train\n",
    "        else:\n",
    "            return self.n_test\n",
    "    \n",
    "    def get_example(self, i):\n",
    "        if self.train:\n",
    "            train = datasets.tuple_dataset.TupleDataset(self.X_train, self.y_train)\n",
    "            return train[i]\n",
    "        else:\n",
    "            test = datasets.tuple_dataset.TupleDataset(self.X_test, self.y_test)\n",
    "            return test[i]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(chainer.Chain):\n",
    "    def __init__(self, n_vocab=1670966, n_units=100):\n",
    "        super(RNN, self).__init__(\n",
    "            embed = L.EmbedID(n_vocab, n_units),\n",
    "            l1 = L.LSTM(None, n_units),\n",
    "            l2 = L.LSTM(None, n_units),\n",
    "            l3 = L.Linear(None, 2)\n",
    "        )\n",
    "    \n",
    "    def reset_state(self):\n",
    "        self.l1.reset_state()\n",
    "        self.l2.reset_state()\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = self.embed(x)\n",
    "        h1 = self.l1(F.dropout(h0))\n",
    "        h2 = self.l2(F.dropout(h1))\n",
    "        y = F.softmax(self.l3(h2))\n",
    "        return y\n",
    "\n",
    "\n",
    "model = L.Classifier(RNN())\n",
    "\n",
    "gpu_id = 0\n",
    "if gpu_id >= 0:\n",
    "    model.to_gpu(gpu_id)\n",
    "    \n",
    "optimizer = chainer.optimizers.Adam()\n",
    "optimizer.setup(model)\n",
    "optimizer.add_hook(chainer.optimizer.GradientClipping(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "MAX_EPOCH = 5\n",
    "# length of truncated BPTT\n",
    "BPROP_LEN = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2179: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "train = jigsaw_dataset(X, y)\n",
    "test = jigsaw_dataset(X, y, train_size=0.9, train=False)\n",
    "del X\n",
    "del y\n",
    "train_iter = chainer.iterators.SerialIterator(train, BATCH_SIZE)\n",
    "test_iter = chainer.iterators.SerialIterator(test, BATCH_SIZE, repeat=False, shuffle=False)\n",
    "del train\n",
    "del test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\t0\n",
      "200\t0\n",
      "300\t1\n",
      "400\t1\n",
      "500\t1\n",
      "600\t2\n",
      "700\t2\n",
      "800\t2\n",
      "900\t3\n",
      "1000\t3\n",
      "1100\t3\n",
      "1200\t4\n",
      "1300\t4\n",
      "1400\t4\n",
      "CPU times: user 9min 52s, sys: 3min 15s, total: 13min 7s\n",
      "Wall time: 13min 9s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sum_perp = 0\n",
    "count = 0\n",
    "iteration = 0\n",
    "while train_iter.epoch < MAX_EPOCH:\n",
    "        loss = 0\n",
    "        iteration += 1\n",
    "        for i in range(BPROP_LEN):\n",
    "            train_batch = train_iter.__next__()\n",
    "            sentence_train, target_train = chainer.dataset.convert.concat_examples(train_batch, gpu_id)\n",
    "            loss += optimizer.target(sentence_train, target_train)\n",
    "            if train_iter.is_new_epoch:\n",
    "                break\n",
    "        count += 1\n",
    "        sum_perp += loss.array\n",
    "        optimizer.target.cleargrads()\n",
    "        loss.backward()\n",
    "        loss.unchain_backward()\n",
    "        optimizer.update()\n",
    "        # 1082924\n",
    "        if count%100==0:\n",
    "            print(str(count)+\"\\t\"+str(train_iter.epoch))\n",
    "del train_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:1: DeprecationWarning: free_all_free is deprecated. Use free_all_blocks instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "cuda.memory_pool.free_all_free()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "out of memory to allocate 17152000 bytes (total 15642199040 bytes)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-45d92d1f8060>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtest_batch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_iter\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0msentence_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat_examples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgpu_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mtest_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/chainer/link.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    240\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforward\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m             \u001b[0mforward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 242\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[0;31m# Call forward_postprocess hook\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/chainer/links/model/classifier.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlossfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0mreporter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreport\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/chainer/link.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    240\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforward\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m             \u001b[0mforward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 242\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[0;31m# Call forward_postprocess hook\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-58e5824402a2>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mh0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mh1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mh2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/chainer/functions/noise/dropout.py\u001b[0m in \u001b[0;36mdropout\u001b[0;34m(x, ratio, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mconfiguration\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mratio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m         \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m         \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/chainer/function_node.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    261\u001b[0m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstatic_forward_optimizations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 263\u001b[0;31m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m         \u001b[0;31m# Check for output array types\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/chainer/function_node.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    367\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 369\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_gpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    370\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_cpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/chainer/functions/noise/dropout.py\u001b[0m in \u001b[0;36mforward_gpu\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     71\u001b[0m                     ''',\n\u001b[1;32m     72\u001b[0m                     \u001b[0;34m'dropout_fwd'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m                 )(x[0], rand, scale, self.dropout_ratio)\n\u001b[0m\u001b[1;32m     74\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mcupy/core/_kernel.pyx\u001b[0m in \u001b[0;36mcupy.core._kernel.ElementwiseKernel.__call__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mcupy/core/_kernel.pyx\u001b[0m in \u001b[0;36mcupy.core._kernel._get_out_args_with_params\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mcupy/core/core.pyx\u001b[0m in \u001b[0;36mcupy.core.core.ndarray.__init__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mcupy/cuda/memory.pyx\u001b[0m in \u001b[0;36mcupy.cuda.memory.alloc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mcupy/cuda/memory.pyx\u001b[0m in \u001b[0;36mcupy.cuda.memory.MemoryPool.malloc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mcupy/cuda/memory.pyx\u001b[0m in \u001b[0;36mcupy.cuda.memory.MemoryPool.malloc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mcupy/cuda/memory.pyx\u001b[0m in \u001b[0;36mcupy.cuda.memory.SingleDeviceMemoryPool.malloc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mcupy/cuda/memory.pyx\u001b[0m in \u001b[0;36mcupy.cuda.memory.SingleDeviceMemoryPool._malloc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mcupy/cuda/memory.pyx\u001b[0m in \u001b[0;36mcupy.cuda.memory._try_malloc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: out of memory to allocate 17152000 bytes (total 15642199040 bytes)"
     ]
    }
   ],
   "source": [
    "test_loss = 0\n",
    "for test_batch in test_iter:\n",
    "    sentence_test, target_test = chainer.dataset.convert.concat_examples(train_batch, gpu_id)\n",
    "    test_loss += optimizer.target(sentence_test, target_test)\n",
    "print(test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df = pd.read_csv(\"../input/sample_submission.csv\")\n",
    "sub_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
