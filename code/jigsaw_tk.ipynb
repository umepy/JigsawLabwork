{"cells":[{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import chainer\nfrom chainer import datasets\nfrom chainer import functions as F\nfrom chainer import links as L\nfrom chainer import Variable\nfrom chainer.backends import cuda\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import roc_auc_score\nimport nltk\nimport re\nimport gensim\nfrom tqdm import tqdm\nimport gc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xp = cuda.cupy\nwnl = nltk.stem.WordNetLemmatizer()\nhead_check = re.compile('^[A-Z][^A-Z]+$')\nURL_slash = re.compile('^//[A-Za-z/.]+')\nURL_www = re.compile('^www[A-Za-z/.]+')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"MIN_COUNT = 10\nBATCH_SIZE = 256\nMAX_EPOCH = 10\n# length of truncated BPTT\nBPROP_LEN = 20\nVECTOR_SIZE = 300\nTRAIN_SIZE = 0.75\nP = 0.4","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = pd.read_csv(\"../input/jigsaw-unintended-bias-in-toxicity-classification/train.csv\")\ntest_df = pd.read_csv(\"../input/jigsaw-unintended-bias-in-toxicity-classification/test.csv\")\nall_df = pd.concat([train_df['comment_text'], test_df['comment_text']])\n\ny= np.where(train_df['target']>=0.5, 1, 0)\ny = y.astype(np.int32)\n# y = np.array(train_df['target'], dtype=np.float32)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"t_all = []\nfor s in tqdm(all_df.values):\n    t_all.append(nltk.word_tokenize(s))\n\ndel all_df\ndel train_df\ndel test_df\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"s_all = []\n\nfor i in range(len(t_all)):\n    vector = []\n    for t in t_all[i]:\n        check = head_check.match(t)\n        if check is not None:\n            add = t[0].lower() + t[1:]\n        elif URL_slash.match(t) is not None or URL_www.match(t):\n            add = \"URL_text\"\n        else:\n            add = t\n        vector.append(wnl.lemmatize(add))\n    s_all.append(vector)\n\ndel t_all\ndel head_check\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"word2vec = gensim.models.word2vec.Word2Vec.load('../input/word2vec-model/word2vec.model')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"t_train = []\nt_pre = []\nfor i in range(len(y)):\n    t_train.append(s_all[i])\nfor i in range(len(y),len(s_all)):\n    t_pre.append(s_all[i])\n\ndel s_all\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"i2w = word2vec.wv.index2word\nwords = {w: i for i, w in enumerate(i2w)}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"zero_index = []\nfor i in range(len(t_train)):\n    vector = []\n    for t in t_train[i]:\n        if t in words:\n            vector.append(words[t])\n        else:\n            vector.append(0)\n    if np.sum(vector)==0:\n        zero_index.append(i)\n\nt_train = np.delete(t_train, zero_index)\ny = np.delete(y, zero_index)\n\ndel vector","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y0_index = np.where(y<0.5)[0]\ny1_index = np.where(y>=0.5)[0]\ny_list = []\nx_list = []\nwhile True:\n    random = np.random.binomial(BATCH_SIZE, P)\n    if len(y1_index)<random or len(y0_index)<(BATCH_SIZE-random):\n        break\n    index = []\n    for i in y1_index[:random]:\n        index.append(i)\n    for i in y0_index[:(BATCH_SIZE-random)]:\n        index.append(i)\n    np.random.shuffle(index)\n    \n    for i in index:\n        x_list.append(t_train[i])\n        y_list.append(y[i])\n         \n    for i in range(random):\n        y1_index = np.delete(y1_index, 0)\n    for i in range(BATCH_SIZE-random):\n        y0_index = np.delete(y0_index, 0)\n\ndel t_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"zero = np.zeros((VECTOR_SIZE,), dtype=np.float32)\nX = []\nfor i in range(len(x_list)):\n    vector = []\n    for s in x_list[i]:\n        try:\n            vector.append(word2vec[s])\n        except KeyError:\n            vector.append(zero)\n    X.append(vector)\n\ny = np.array(y_list, dtype=np.int32)\n\ndel x_list, y_list","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"max_len_train = max(list(map(len, X)))\nmax_len_test = max(list(map(len, t_pre)))\nmax_len = max_len_train if max_len_train>max_len_test else max_len_test\ndel max_len_train\ndel max_len_test\n\nfor i in range(len(X)):\n    diff = max_len - len(X[i])\n    for j in range(diff):\n        X[i].append(zero)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=TRAIN_SIZE)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class jigsaw_dataset(chainer.dataset.DatasetMixin):\n    def __init__(self, X, y):\n        self.X_train = X\n        self.y_train = y\n        self.n_train = len(self.y_train)\n    def __len__(self):\n        return self.n_train\n        \n    def get_example(self, i):\n        train = datasets.tuple_dataset.TupleDataset(self.X_train, self.y_train)\n        return train[i]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class RNN(chainer.Chain):\n    def __init__(self, n_units=300):\n        super(RNN, self).__init__(\n            l1 = L.Linear(None, n_units),\n            l2 = L.LSTM(None, n_units),\n            l3 = L.LSTM(None, n_units),\n            l4 = L.Linear(None, 2)\n        )\n    \n    def reset_state(self):\n        self.l2.reset_state()\n        self.l3.reset_state()\n\n    def forward(self, x):\n        h1 = F.sigmoid(self.l1(x))\n        h2 = self.l2(F.dropout(h1))\n        h3 = self.l3(F.dropout(h2))\n        y = F.softmax(self.l4(h3))\n        return y\n\n\nmodel = L.Classifier(RNN(n_units=300))\n\ngpu_id = 0\nif gpu_id >= 0:\n    model.to_gpu(gpu_id)\n    \noptimizer = chainer.optimizers.Adam()\noptimizer.setup(model)\noptimizer.add_hook(chainer.optimizer.GradientClipping(5))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def evaluate(model, X_test, y_test):\n    evaluator = model.copy()\n    evaluator.predictor.reset_state()\n    p_list = []\n    auc = 0\n    with chainer.configuration.using_config('train', False):\n        with chainer.using_config('enable_backprop', False):\n            for i in range(len(X_test)):\n                p = xp.array([X_test[i]])\n                prediction = evaluator.predictor(p)\n                p_cpu = cuda.to_cpu(prediction.array)\n                p_list.append(p_cpu[0][y_test[i]])\n\n            auc = roc_auc_score(y_test, np.array(p_list))\n    return auc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = jigsaw_dataset(X_train, y_train)\ntrain_iter = chainer.iterators.SerialIterator(train, BATCH_SIZE)\ndel X_train\ndel y_train\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_iter.reset()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nsum_perp = 0\niteration = 0\nwhile train_iter.epoch < MAX_EPOCH:\n        loss = 0\n        iteration += 1\n        for i in range(BPROP_LEN):\n            train_batch = train_iter.__next__()\n            sentence_train, target_train = chainer.dataset.convert.concat_examples(train_batch, gpu_id)\n            loss += optimizer.target(sentence_train, target_train)\n            if train_iter.is_new_epoch:\n                break\n        sum_perp += loss.array\n        optimizer.target.cleargrads()\n        loss.backward()\n        loss.unchain_backward()\n        optimizer.update()\n        if train_iter.is_new_epoch:\n            print('epoch:{}'.format(train_iter.epoch))\n            print('test perplexity:{0:10f}'.format(evaluate(model, X_test, y_test)))\n# del train_iter","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_pre = []\nfor i in range(len(t_pre)):\n    vector = []\n    for s in t_pre[i]:\n        try:\n            vector.append(word2vec[s])\n        except KeyError:\n            vector.append(zero)\n    X_pre.append(vector)\n\n# del t_pre\n\nfor i in range(len(X_pre)):\n    diff = max_len - len(X_pre[i])\n    for j in range(diff):\n        X_pre[i].append(zero)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def predictor(model, X_pre):\n    prediction_cpu = []\n    with chainer.configuration.using_config('train', False):\n        with chainer.using_config('enable_backprop', False):\n            for i in range(len(X_pre)):\n                p = xp.array([X_pre[i]])\n                prediction = model.predictor(p)\n                del p\n                p_cpu = cuda.to_cpu(prediction.array)\n                del prediction\n                prediction_cpu.append(p_cpu)\n    return prediction_cpu","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pre_df = pd.read_csv(\"../input/jigsaw-unintended-bias-in-toxicity-classification/sample_submission.csv\")\npre_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pre_df.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prediction_cpu = predictor(model, X_pre)\n\nfor i in range(len(prediction_cpu)):\n#     p = np.where(prediction_cpu[i][0][0] > prediction_cpu[i][0][1], 0, 1)\n    p = prediction_cpu[i][0][1]\n    pre_df.loc[i, 'prediction'] = p","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%matplotlib inline\npre_df['prediction'].plot.hist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pre_df.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pre_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pre_df.tail()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"}},"nbformat":4,"nbformat_minor":1}