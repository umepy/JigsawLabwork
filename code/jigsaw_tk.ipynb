{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"../input\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chainer\n",
    "from chainer import datasets\n",
    "from chainer import functions as F\n",
    "from chainer import links as L\n",
    "from chainer import Variable\n",
    "from chainer.backends import cuda\n",
    "from sklearn.model_selection import train_test_split\n",
    "import nltk\n",
    "import re\n",
    "import gensim\n",
    "from tqdm import tqdm\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xp = cuda.cupy\n",
    "wnl = nltk.stem.WordNetLemmatizer()\n",
    "head_check = re.compile('^[A-Z][^A-Z]+$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_COUNT = 10\n",
    "BATCH_SIZE = 128\n",
    "MAX_EPOCH = 3\n",
    "# length of truncated BPTT\n",
    "BPROP_LEN = 20\n",
    "VECTOR_SIZE = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "train_df = pd.read_csv(\"../input/jigsaw-unintended-bias-in-toxicity-classification/train.csv\")\n",
    "test_df = pd.read_csv(\"../input/jigsaw-unintended-bias-in-toxicity-classification/test.csv\")\n",
    "all_df = pd.concat([train_df['comment_text'], test_df['comment_text']])\n",
    "\n",
    "y= np.where(train_df['target']>=0.5, 1, 0)\n",
    "y = y.astype(np.int32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_all = []\n",
    "for s in tqdm(all_df.values):\n",
    "    t_all.append(nltk.word_tokenize(s))\n",
    "\n",
    "del all_df\n",
    "del train_df\n",
    "del test_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_all = []\n",
    "\n",
    "for i in range(len(t_all)):\n",
    "    vector = []\n",
    "    for t in t_all[i]:\n",
    "        check = head_check.match(t)\n",
    "        if check is not None:\n",
    "            add = t[0].lower() + t[1:]\n",
    "        else:\n",
    "            add = t\n",
    "        vector.append(wnl.lemmatize(add))\n",
    "    s_all.append(vector)\n",
    "\n",
    "del t_all\n",
    "del head_check\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(s_all), s_all[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec = gensim.models.word2vec.Word2Vec.load('../input/word2vec-model/word2vec.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_train = []\n",
    "t_pre = []\n",
    "for i in range(len(y)):\n",
    "    t_train.append(s_all[i])\n",
    "for i in range(len(y),len(s_all)):\n",
    "    t_pre.append(s_all[i])\n",
    "\n",
    "del s_all\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1660540, 144334)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_df = pd.DataFrame(y, columns=['y'])\n",
    "y_tf = y_df==0\n",
    "y0 = y_tf.sum()\n",
    "y0 = y0[0]\n",
    "y1 = len(y_df)-y0\n",
    "y0, y1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.binomial(128, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_sort = y_df.sort_values('y', ascending=False)\n",
    "y1_df = pd.DataFrame(y_sort[0:y1], columns=['y1'])\n",
    "y0_df = pd.DataFrame(y_sort[y1:], columns=['y0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fd4a6fd5400>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_df.plot.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero = np.zeros((VECTOR_SIZE,), dtype=np.float32)\n",
    "X = []\n",
    "for i in range(len(t_train)):\n",
    "    vector = []\n",
    "    for s in t_train[i]:\n",
    "        try:\n",
    "            vector.append(word2vec[s])\n",
    "        except KeyError:\n",
    "            vector.append(zero)\n",
    "    X.append(vector)\n",
    "    \n",
    "del t_train\n",
    "# del vector\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len_train = max(list(map(len, X)))\n",
    "max_len_test = max(list(map(len, X_pre)))\n",
    "max_len = max_len_train if max_len_train>max_len_test else max_len_test\n",
    "del max_len_train\n",
    "del max_len_test\n",
    "\n",
    "for i in range(len(X)):\n",
    "    diff = max_len - len(X[i])\n",
    "    for j in range(diff):\n",
    "        X[i].append(zero)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i2w = word2vec.wv.index2word\n",
    "# words = {w: i for i, w in enumerate(i2w)}\n",
    "\n",
    "# for i in range(len(t_all)):\n",
    "#     for word in t_all[i]:\n",
    "#         if word not in words:\n",
    "#             words[word] = -1\n",
    "\n",
    "# del t_all\n",
    "\n",
    "# X = []\n",
    "# for j in range(len(t_train)):\n",
    "#     vector = []\n",
    "#     for word in t_train[j]:\n",
    "#         try:\n",
    "#             vector.append(words[word])\n",
    "#         except KeyError:\n",
    "#             words[word] = -1\n",
    "#             vector.append(words[word])\n",
    "#     vector = np.array(vector, dtype=np.int32)\n",
    "#     X.append(vector)\n",
    "\n",
    "# X_pre = []\n",
    "# for j in range(len(t_pre)):\n",
    "#     vector = []\n",
    "#     for word in t_pre[j]:\n",
    "#         try:\n",
    "#             vector.append(words[word])\n",
    "#         except KeyError:\n",
    "#             words[word] = -1\n",
    "#             vector.append(words[word])\n",
    "#     vector = np.array(vector, dtype=np.int32)\n",
    "#     X_pre.append(vector)\n",
    "\n",
    "# del t_train\n",
    "# del t_pre\n",
    "# del words\n",
    "# del vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_len_train = max(list(map(len, X)))\n",
    "# max_len_test = max(list(map(len, X_pre)))\n",
    "# max_len = max_len_train if max_len_train>max_len_test else max_len_test\n",
    "# del max_len_train\n",
    "# del max_len_test\n",
    "\n",
    "# for i in range(len(X)):\n",
    "#     add = np.zeros((max_len-len(X[i])), dtype=np.int32)\n",
    "#     X[i] = np.append(X[i], add)\n",
    "\n",
    "# for i in range(len(X_pre)):\n",
    "#     add = np.zeros((max_len-len(X_pre[i])), dtype=xp.int32)\n",
    "#     X_pre[i] = np.append(X_pre[i], add)\n",
    "\n",
    "# del add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class jigsaw_dataset(chainer.dataset.DatasetMixin):\n",
    "    def __init__(self, X, y, train=True, train_size=0.6):\n",
    "        \n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(X, y, train_size=train_size, random_state=1)\n",
    "        self.n_train = len(self.y_train)\n",
    "        self.n_test = len(self.y_test)\n",
    "        self.train = train\n",
    "        self.train_size=train_size\n",
    "    \n",
    "    def __len__(self):\n",
    "        if self.train:\n",
    "            return self.n_train\n",
    "        else:\n",
    "            return self.n_test\n",
    "    \n",
    "    def get_example(self, i):\n",
    "        if self.train:\n",
    "            train = datasets.tuple_dataset.TupleDataset(self.X_train, self.y_train)\n",
    "            return train[i]\n",
    "        else:\n",
    "            test = datasets.tuple_dataset.TupleDataset(self.X_test, self.y_test)\n",
    "            return test[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X[0]), len(X[1]), len(X_pre[0]), len(X_pre[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class RNN(chainer.Chain):\n",
    "#     def __init__(self, n_vocab=1000, n_units=100, w=None):\n",
    "#         super(RNN, self).__init__(\n",
    "#             embed = L.EmbedID(n_vocab, n_units, initialW=w),\n",
    "#             l1 = L.LSTM(None, n_units),\n",
    "#             l2 = L.LSTM(None, n_units),\n",
    "#             l3 = L.Linear(None, 2)\n",
    "#         )\n",
    "    \n",
    "#     def reset_state(self):\n",
    "#         self.l1.reset_state()\n",
    "#         self.l2.reset_state()\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         print(x)\n",
    "#         h0 = self.embed(x)\n",
    "#         h1 = self.l1(F.dropout(h0))\n",
    "#         h2 = self.l2(F.dropout(h1))\n",
    "#         y = F.softmax(self.l3(h2))\n",
    "#         return y\n",
    "\n",
    "\n",
    "# model = L.Classifier(RNN(n_vocab=word2vec.wv.vectors.shape[0],n_units=word2vec.wv.vectors.shape[1], w=word2vec.wv.vectors))\n",
    "\n",
    "# gpu_id = 0\n",
    "# if gpu_id >= 0:\n",
    "#     model.to_gpu(gpu_id)\n",
    "    \n",
    "# optimizer = chainer.optimizers.Adam()\n",
    "# optimizer.setup(model)\n",
    "# optimizer.add_hook(chainer.optimizer.GradientClipping(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(chainer.Chain):\n",
    "    def __init__(self, n_units=300):\n",
    "        super(RNN, self).__init__(\n",
    "            l1 = L.LSTM(None, n_units),\n",
    "            l2 = L.LSTM(None, n_units),\n",
    "            l3 = L.Linear(None, 2)\n",
    "        )\n",
    "    \n",
    "    def reset_state(self):\n",
    "        self.l1.reset_state()\n",
    "        self.l2.reset_state()\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = self.l1(F.dropout(x))\n",
    "        h1 = self.l2(F.dropout(h1))\n",
    "        y = F.softmax(self.l3(h2))\n",
    "        return y\n",
    "\n",
    "\n",
    "model = L.Classifier(RNN(n_units=300))\n",
    "\n",
    "gpu_id = 0\n",
    "if gpu_id >= 0:\n",
    "    model.to_gpu(gpu_id)\n",
    "    \n",
    "optimizer = chainer.optimizers.Adam()\n",
    "optimizer.setup(model)\n",
    "optimizer.add_hook(chainer.optimizer.GradientClipping(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = jigsaw_dataset(X, y)\n",
    "test = jigsaw_dataset(X, y, train=False)\n",
    "del X\n",
    "del y\n",
    "train_iter = chainer.iterators.SerialIterator(train, BATCH_SIZE)\n",
    "test_iter = chainer.iterators.SerialIterator(test, BATCH_SIZE, repeat=False, shuffle=False)\n",
    "del train\n",
    "del test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, iter, gpu_id):\n",
    "    evaluator = model.copy()\n",
    "    evaluator.predictor.reset_state()\n",
    "    sum_perp = 0\n",
    "    data_count = 0\n",
    "    with chainer.configuration.using_config('train', False):\n",
    "        with chainer.using_config('enable_backprop', False):\n",
    "            iter.reset()\n",
    "            for batch in iter:\n",
    "                sentence, target = chainer.dataset.convert.concat_examples(batch, gpu_id)\n",
    "                loss = evaluator(sentence, target)\n",
    "                sum_perp += loss.array\n",
    "                data_count += 1\n",
    "    return np.exp(float(sum_perp) / data_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sum_perp = 0\n",
    "count = 0\n",
    "iteration = 0\n",
    "while train_iter.epoch < MAX_EPOCH:\n",
    "        loss = 0\n",
    "        iteration += 1\n",
    "        for i in range(BPROP_LEN):\n",
    "            train_batch = train_iter.__next__()\n",
    "            sentence_train, target_train = chainer.dataset.convert.concat_examples(train_batch, gpu_id)\n",
    "            loss += optimizer.target(sentence_train, target_train)\n",
    "            if train_iter.is_new_epoch:\n",
    "                break\n",
    "        count += 1\n",
    "        sum_perp += loss.array\n",
    "        optimizer.target.cleargrads()\n",
    "        loss.backward()\n",
    "        loss.unchain_backward()\n",
    "        optimizer.update()\n",
    "        print(count)\n",
    "        # 1082924\n",
    "        if train_iter.is_new_epoch:\n",
    "            print('epoch:{}'.format(train_iter.epoch))\n",
    "            print('test perplexity:{}'.format(evaluate(model, test_iter, gpu_id)))\n",
    "del train_iter\n",
    "del test_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pre = []\n",
    "for i in range(len(t_pre)):\n",
    "    vector = []\n",
    "    for s in t_pre[i]:\n",
    "        try:\n",
    "            vector.append(word2vec[s])\n",
    "        except KeyError:\n",
    "            vector.append(zero)\n",
    "    X_pre.append(vector)\n",
    "\n",
    "del t_pre\n",
    "\n",
    "for i in range(len(X_pre)):\n",
    "    diff = max_len - len(X_pre[i])\n",
    "    for j in range(diff):\n",
    "        X_pre[i].append(zero)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictor(model, X_pre):\n",
    "    prediction_cpu = []\n",
    "    with chainer.configuration.using_config('train', False):\n",
    "        with chainer.using_config('enable_backprop', False):\n",
    "            for i in range(len(X_pre)):\n",
    "#                 print(i)\n",
    "                p = xp.array([X_pre[i]])\n",
    "                prediction = model.predictor(p)\n",
    "                del p\n",
    "                p_cpu = cuda.to_cpu(prediction.array)\n",
    "                del prediction\n",
    "                prediction_cpu.append(p_cpu)\n",
    "    return prediction_cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_cpu = predictor(model, X_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_df = pd.read_csv(\"../input/sample_submission.csv\")\n",
    "pre_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for i in range(len(prediction_cpu)):\n",
    "    p = np.where(prediction_cpu[i][0][0] > prediction_cpu[i][0][1], 0, 1)\n",
    "    pre_df.loc[i, 'prediction'] = p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_df['prediction'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_df.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
